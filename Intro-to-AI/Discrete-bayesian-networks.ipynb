{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC421 Assignment 4 - Part I Discrete Bayesian Networks (5 points) #\n",
    "### Author: George Tzanetakis \n",
    "\n",
    "This notebook is based on the supporting material for topics covered in **Chapter 14 Probabilistic Reasoning** from the book *Artificial Intelligence: A Modern Approach.* \n",
    "\n",
    "This part relies on the provided notebook code probability.ipynb \n",
    "\n",
    "```\n",
    "Misunderstanding of probability may be the greatest of all impediments\n",
    "to scientific literacy.\n",
    "\n",
    "Gould, Stephen Jay\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this part of assignment 4 we will be exploring Discrete Bayesian Networks (DBNs) and answering queries with exact and approximate inference methods. We will be using the following network: \n",
    "\n",
    "<img src=\"dispnea.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1A (Minimum) CSC421 -  (1 point, CSC581C - 0 points) \n",
    "\n",
    "Using the convetions for DBNs used in probability.ipynb (from the AIMA authors) encode the diapnea network shown above. Once you have constructed the Bayesian network display the cpt for the Lung Cancer Node (using the API provided not just showing the numbers). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lung Cancer?\n",
      "╒═══════╤═══════════════╕\n",
      "│ S     │   Probability │\n",
      "╞═══════╪═══════════════╡\n",
      "│ True  │           0.1 │\n",
      "├───────┼───────────────┤\n",
      "│ False │          0.01 │\n",
      "╘═══════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "from probability import *\n",
    "from utils import print_table\n",
    "from tabulate import*\n",
    "\n",
    "A = ('A', '', 0.01)\n",
    "S = ('S', '', 0.5)\n",
    "T = ('T', ['A'], {True: 0.05, False: 0.01})\n",
    "L = ('L', ['S'], {True: 0.1, False: 0.01})\n",
    "B = ('B', ['S'], {True: 0.6, False: 0.3})\n",
    "E = ('E', ['L', 'T'], {(True, True): 1.0, (True, False): 1.0, (False, True): 1.0, (False, False): 0.0})\n",
    "X = ('X', ['E'], {True: 0.98, False: 0.05})\n",
    "D = ('D', ['E', 'B'], {(True, True): 0.9, (True, False): 0.7, (False, True): 0.8, (False, False): 0.1})\n",
    "\n",
    "dyspnea = BayesNet([A, S, T, L, B, E, X, D])\n",
    "\n",
    "Headers = [dyspnea.variable_node('L').parents[0], 'Probability']\n",
    "Data = [['True', dyspnea.variable_node('L').cpt[(True,)]],\n",
    "        ['False', dyspnea.variable_node('L').cpt[(False,)]]\n",
    "       ]\n",
    "\n",
    "print('Lung Cancer?')\n",
    "print(tabulate(Data,Headers,tablefmt=\"fancy_grid\", numalign = \"right\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1B (Minimum) (CSC421 - 1 point, CSC581C - 0 point) \n",
    "\n",
    "Answer using exact inference with enumeration the following query: given that a\n",
    "patient has been in Asia and has a positive xray, what is the likelihood of having dyspnea?\n",
    "\n",
    "Write down using markdown the expression that corresponds to this query and the corresponding \n",
    "numbers from the CPT. Calculate the result using a calculator. \n",
    "\n",
    "Write code for the same query using *enumeration_ask* and confirm that the result is the same for the same query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(D|A,X)\n",
    "= P(A)P(S)Σ(T)P(T|A)Σ(L)P(L|S)Σ(B)P(B|S)Σ(E)P(E|L,T)P(X|E)P(D|E,B)\n",
    "\n",
    "P(T) = P(T|A)P(A) = (0.05)(1) = 0.05\n",
    "P(L) = Σs P(L|S)P(S) = (0.1)(0.5) + (0.01)(0.5) = 0.055\n",
    "P(B) = Σs P(B|S)P(S) = (0.6)(0.5) + (0.3)(0.5) = 0.45\n",
    "P(E) = Σl,t P(E|L,T)P(L)P(T) = (1)(0.055)(0.05) + (1)(0.055)(0.95) + (1)(0.945)(0.05)\n",
    "     = 0.10225\n",
    "     \n",
    "P(D) = Σe,b P(D|E,B)P(E)P(B)P(X|E) = (0.9)(0.10225)(0.45)(0.98) + (0.7)(0.10225)(0.55)(0.98) + (0.8)(0.89775)(0.45)(0.05) + (0.1)(0.89775)(0.55)(0.05)\n",
    "     = 0.097790262\n",
    "\n",
    "P(~D) = Σe,b P(~D|E,B)P(E)P(B)P(X|E) = (0.1)(0.10225)(0.45)(0.98) + (0.3)(0.10225)(0.55)(0.98) + (0.2)(0.89775)(0.45)(0.05) + (0.9)(0.89775)(0.55)(0.05)\n",
    "      = 0.047302237\n",
    "      \n",
    "alpha is 0.097790262 + 0.047302237 = 0.145092499\n",
    "\n",
    "Normalizing P(D): 0.097790262/0.145092499 = 0.673985646\n",
    "\n",
    "P(D|A,X) = 67.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.319, True: 0.681\n"
     ]
    }
   ],
   "source": [
    "print(enumeration_ask('D', {'X': True, 'A': True}, dyspnea).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1C (Expected) 1 point \n",
    "\n",
    "Answer using variable elimination i.e the function *elimination_ask*  using the same query. Compare the timing using %%timeit the query using *enumeration_ask* and *eliimination_ask*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.319, True: 0.681 \n",
      "\n",
      "enumeration_ask runtime:\n",
      "6.35 ms ± 1.01 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "elimination_ask runtime:\n",
      "13.4 ms ± 250 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(elimination_ask('D', {'X': True, 'A': True}, dyspnea).show_approx(),'\\n')\n",
    "\n",
    "print('enumeration_ask runtime:')\n",
    "%timeit enumeration_ask('D', {'X': True, 'A': True}, dyspnea)\n",
    "print('\\nelimination_ask runtime:')\n",
    "%timeit elimination_ask('D', {'X': True, 'A': True}, dyspnea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4.1D (Expected ) 1 point\n",
    "\n",
    "Answer using approximate inference the same query using both rejection sampling and likelihood weighting. Compare the runtime of the two approximate inference algorithms and the two exact inference algorithms for this query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejection Sampling\n",
      "-------------------------\n",
      "False: 0.4, True: 0.6\n",
      "336 ms ± 7.74 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Likelihood Weighting\n",
      "-------------------------\n",
      "False: 0.309, True: 0.691\n",
      "309 ms ± 30.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print('Rejection Sampling\\n','-'*25,sep='')\n",
    "print(rejection_sampling('D', {'X': True, 'A': True}, dyspnea, 10000).show_approx())\n",
    "%timeit rejection_sampling('D', {'X': True, 'A': True}, dyspnea, 10000).show_approx()\n",
    "\n",
    "print('\\nLikelihood Weighting\\n','-'*25,sep='')\n",
    "print(likelihood_weighting('D', {'X': True, 'A': True}, dyspnea, 10000).show_approx())\n",
    "%timeit likelihood_weighting('D', {'X': True, 'A': True}, dyspnea).show_approx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4.1E (Advanced) 1 point \n",
    "\n",
    "A Naive Bayes classifier can be considered as a Bayesian Network. The classification problem can then be expressed as setting all the variables corresponding to the features as evidence and querying the probability for the class. Express the Bernoulli Naive Bayes classifier you implemented in the previous assignment as a Bayesian Network using the probability.ipynb conventions. Now that you have a DBN express and solve the classification problem as a query and go over all the previous steps for this particular problem. More specifically do exact inference by enumeration, exact inference by variable elimination, approximate inference by rejection sampling and approximate inference by likelihood weighting to answer the query and show the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification using enumeration_ask\n",
      "------------------------------\n",
      "Positive? False: 0.879, True: 0.121\n",
      "Negative? False: 0.892, True: 0.108\n",
      "Prediction: the review is positive\n",
      "\n",
      "Classification using elimination_ask\n",
      "------------------------------\n",
      "Positive? False: 0.879, True: 0.121\n",
      "Negative? False: 0.892, True: 0.108\n",
      "Prediction: the review is positive\n",
      "\n",
      "Classification using rejection_sampling\n",
      "------------------------------\n",
      "Positive? False: 0.882, True: 0.118\n",
      "Negative? False: 0.891, True: 0.109\n",
      "Prediction: the review is positive\n",
      "\n",
      "Classification using likelihood_weighting\n",
      "------------------------------\n",
      "Positive? False: 0.878, True: 0.122\n",
      "Negative? False: 0.892, True: 0.108\n",
      "Prediction: the review is positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_probs = [0.019, 0.254, 0.048, 0.023, 0.120, 0.094, 0.405, 0.125]\n",
    "neg_probs = [0.099, 0.503, 0.166, 0.090, 0.046, 0.053, 0.282, 0.048]\n",
    "\n",
    "pos_cpt = {}\n",
    "neg_cpt = {}\n",
    "\n",
    "cpt_keys = [[]]\n",
    "\n",
    "#create a list of all possible variable assignments\n",
    "for i in range(0,8):\n",
    "    for item in cpt_keys[::1]:\n",
    "        copy = item.copy()\n",
    "        item.append(True)\n",
    "        copy.append(False)\n",
    "        cpt_keys.append(copy)\n",
    "\n",
    "#complete cpt for the positive node\n",
    "for cp in cpt_keys:\n",
    "    prob = 1\n",
    "    for i,value in enumerate(cp):\n",
    "        if value == True: prob = prob*pos_probs[i]\n",
    "        else: prob = prob*(1-pos_probs[i])\n",
    "    pos_cpt[tuple(cp)]=prob\n",
    "\n",
    "#complete cpt for the negative node\n",
    "for cp in cpt_keys:\n",
    "    prob = 1\n",
    "    for i,value in enumerate(cp):\n",
    "        if value == True: prob = prob*neg_probs[i]\n",
    "        else: prob = prob*(1-neg_probs[i])\n",
    "    neg_cpt[tuple(cp)]=prob\n",
    "\n",
    "#word probabilities are irrelevant; we will have their values as evidence in all queries\n",
    "Aw = ('awful', '', 0.059)\n",
    "Ba = ('bad', '', 0.3785)\n",
    "Bo = ('boring', '', 0.107)\n",
    "Du = ('dull', '', 0.0565)\n",
    "Ef = ('effective', '', 0.083)\n",
    "En = ('enjoyable', '', 0.0735)\n",
    "Gr = ('great', '', 0.3435)\n",
    "Hi = ('hilarious', '', 0.0865)\n",
    "Po = ('Pos', ['awful','bad','boring','dull','effective','enjoyable','great','hilarious'], pos_cpt)\n",
    "Ne = ('Neg', ['awful','bad','boring','dull','effective','enjoyable','great','hilarious'], neg_cpt)\n",
    "\n",
    "video_review = BayesNet([Aw, Ba, Bo, Du, Ef, En, Gr, Hi, Po, Ne, ])\n",
    "review_sample = {'Aw': False, \n",
    "                  'Ba': False, \n",
    "                  'Bo': False,\n",
    "                  'Du': False,\n",
    "                  'Ef': False,\n",
    "                  'En': True,\n",
    "                  'Gr': True,\n",
    "                  'Hi': False}\n",
    "\n",
    "def classify(sample, method):\n",
    "    print('Classification using', method.__name__)\n",
    "    print('-'*30)\n",
    "    pos = method('Pos', sample, video_review).show_approx()\n",
    "    neg = method('Neg', sample, video_review).show_approx()\n",
    "    print('Positive?',pos)\n",
    "    print('Negative?',neg)\n",
    "    if pos[True] >= neg[True]:\n",
    "        print('Prediction: the review is positive')\n",
    "    else:\n",
    "        print('Prediction: the review is negative')\n",
    "    print()\n",
    "\n",
    "classify(review_sample, enumeration_ask)\n",
    "classify(review_sample, elimination_ask)\n",
    "classify(review_sample, rejection_sampling)\n",
    "classify(review_sample, likelihood_weighting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
